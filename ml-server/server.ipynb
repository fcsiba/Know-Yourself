{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "from flask import request\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = load_model('my_model.h5')\n",
    "ps = PorterStemmer()\n",
    "\n",
    "file = open('processed_list_of_tweets.pkl', 'rb')\n",
    "text_data = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "x = (int)(len(text_data) * 0.8)\n",
    "training_text = text_data[0:x]\n",
    "\n",
    "tokenizer = Tokenizer(num_words = 5000, oov_token= '<<none>>')\n",
    "tokenizer.fit_on_texts(training_text)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "def words_only(text):\n",
    "    '''Remove puctuations, underscores, numbers, words containing numbers and @_mentions.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\w*\\#angry\\w*', '', text)\n",
    "    text = re.sub(r'\\w*\\#hate\\w*', '', text)\n",
    "    text = re.sub(r'\\w*\\@\\w*', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]','', text)\n",
    "    text = re.sub(r'\\_','',text)\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    text = re.sub(' +', ' ',text)\n",
    "    return remove_stop_words(text.strip())\n",
    "\n",
    "#nltk.download('punkt')\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    '''Remove stop words and stem the words'''\n",
    "    text_filtered = \"\"\n",
    "    text = word_tokenize(text)\n",
    "    for word in text:\n",
    "        if word not in stopwords.words(\"english\"):\n",
    "            word = ps.stem(word)\n",
    "            text_filtered = text_filtered+\" \"+word\n",
    "    return text_filtered.strip()\n",
    "\n",
    "def predict_the_sentiment(text):\n",
    "    txt2 = words_only(text)\n",
    "    txt = []\n",
    "    txt.append(txt2)\n",
    "    seq = tokenizer.texts_to_sequences(txt)\n",
    "    padded = pad_sequences(seq, maxlen=50, padding='post', truncating='post')\n",
    "\n",
    "    pred = model.predict(padded)\n",
    "    labels = ['happy', 'sad', 'angry', 'hate', 'neutral'] \n",
    "    #print(pred)\n",
    "    #print(np.argmax(pred))\n",
    "    return(labels[np.argmax(pred)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:7001/ (Press CTRL+C to quit)\n",
      "[2020-07-12 23:57:20,270] ERROR in app: Exception on /analysis [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Hassan Sheikh\\.conda\\envs\\fyp\\lib\\site-packages\\flask\\app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"C:\\Users\\Hassan Sheikh\\.conda\\envs\\fyp\\lib\\site-packages\\flask\\app.py\", line 1952, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"C:\\Users\\Hassan Sheikh\\.conda\\envs\\fyp\\lib\\site-packages\\flask\\app.py\", line 1821, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"C:\\Users\\Hassan Sheikh\\.conda\\envs\\fyp\\lib\\site-packages\\flask\\_compat.py\", line 39, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\Hassan Sheikh\\.conda\\envs\\fyp\\lib\\site-packages\\flask\\app.py\", line 1950, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"C:\\Users\\Hassan Sheikh\\.conda\\envs\\fyp\\lib\\site-packages\\flask\\app.py\", line 1936, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-9-5aa6a5d3a7a1>\", line 6, in analysis_data\n",
      "    sentiment = predict_the_sentiment(my_data)\n",
      "  File \"<ipython-input-8-f0a582fa1990>\", line 46, in predict_the_sentiment\n",
      "    pred = model.predict(padded)\n",
      "  File \"C:\\Users\\Hassan Sheikh\\.conda\\envs\\fyp\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 908, in predict\n",
      "    use_multiprocessing=use_multiprocessing)\n",
      "  File \"C:\\Users\\Hassan Sheikh\\.conda\\envs\\fyp\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 723, in predict\n",
      "    callbacks=callbacks)\n",
      "  File \"C:\\Users\\Hassan Sheikh\\.conda\\envs\\fyp\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 189, in model_iteration\n",
      "    f = _make_execution_function(model, mode)\n",
      "  File \"C:\\Users\\Hassan Sheikh\\.conda\\envs\\fyp\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 566, in _make_execution_function\n",
      "    return model._make_execution_function(mode)\n",
      "  File \"C:\\Users\\Hassan Sheikh\\.conda\\envs\\fyp\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 2189, in _make_execution_function\n",
      "    self._make_predict_function()\n",
      "  File \"C:\\Users\\Hassan Sheikh\\.conda\\envs\\fyp\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 2179, in _make_predict_function\n",
      "    **kwargs)\n",
      "  File \"C:\\Users\\Hassan Sheikh\\.conda\\envs\\fyp\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3678, in function\n",
      "    return GraphExecutionFunction(inputs, outputs, updates=updates, **kwargs)\n",
      "  File \"C:\\Users\\Hassan Sheikh\\.conda\\envs\\fyp\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3330, in __init__\n",
      "    with ops.control_dependencies([self.outputs[0]]):\n",
      "  File \"C:\\Users\\Hassan Sheikh\\.conda\\envs\\fyp\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 5254, in control_dependencies\n",
      "    return get_default_graph().control_dependencies(control_inputs)\n",
      "  File \"C:\\Users\\Hassan Sheikh\\.conda\\envs\\fyp\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 4688, in control_dependencies\n",
      "    c = self.as_graph_element(c)\n",
      "  File \"C:\\Users\\Hassan Sheikh\\.conda\\envs\\fyp\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3607, in as_graph_element\n",
      "    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\n",
      "  File \"C:\\Users\\Hassan Sheikh\\.conda\\envs\\fyp\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3686, in _as_graph_element_locked\n",
      "    raise ValueError(\"Tensor %s is not an element of this graph.\" % obj)\n",
      "ValueError: Tensor Tensor(\"dense_1_1/Softmax:0\", shape=(?, 6), dtype=float32) is not an element of this graph.\n",
      "127.0.0.1 - - [12/Jul/2020 23:57:20] \"\u001b[1m\u001b[35mPOST /analysis HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    }
   ],
   "source": [
    "@app.route('/analysis', methods=['POST'])\n",
    "def analysis_data():\n",
    "    if (request.method == 'POST'):\n",
    "        data = json.loads(request.data)\n",
    "        my_data = str(data['data'])\n",
    "        sentiment = predict_the_sentiment(my_data)\n",
    "#         print(str(sentiment))\n",
    "        return my_data\n",
    "    else:\n",
    "        return 'error'\n",
    "if __name__ == '__main__':\n",
    "    app.run('localhost','7001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
